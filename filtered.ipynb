{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN4JcSLjawnT"
      },
      "source": [
        "# GenreMatch\n",
        "Data cleaning and model generation  \n",
        "*Jeremy Freedman, Reza Madhavan, Kunal Sheth*"
      ],
      "id": "MN4JcSLjawnT"
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip Archive.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdHUQFa3dgMx",
        "outputId": "a0254c9b-217b-45f7-bf43-3a89aa01dee0"
      },
      "id": "CdHUQFa3dgMx",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  Archive.zip\n",
            "replace utils/genius.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace utils/grab_lyrics.py? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy9GICSqdrpH",
        "outputId": "14e938d0-d975-4709-ce9c-10562cc138cd"
      },
      "id": "oy9GICSqdrpH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "azlyrics.py  grab_genius.ipynb\t__pycache__\n",
            "genius.py    grab_lyrics.py\tsonglyrics.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "id": "ZRQb4iM7awnV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import songlyrics as sl\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk import download as nltk_download\n",
        "import sklearn as sk\n",
        "from sklearn import tree\n",
        "import collections\n",
        "import gc"
      ],
      "id": "ZRQb4iM7awnV"
    },
    {
      "cell_type": "code",
      "source": [
        "a=pd.read_csv('data/song_lyrics.csv').dropna()\n",
        "new_df = a.copy()\n",
        "head = new_df.head(5)"
      ],
      "metadata": {
        "id": "S7jvCK5HjTtP"
      },
      "id": "S7jvCK5HjTtP",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtGsK4NbawnW",
        "outputId": "528a5e7e-cda7-4e1f-d316-6a5cbcf6c56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# download the NLTK stopwords list, if necessary\n",
        "nltk_download('stopwords')"
      ],
      "id": "mtGsK4NbawnW"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZe4wN0lawnW",
        "outputId": "f31dbdc4-16f8-4b2b-9044-87b79d9a5eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', 'youll', 'youd', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'shes', 'her', 'hers', 'herself', 'it', 'its', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'thatll', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'dont', 'should', 'shouldve', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'arent', 'couldn', 'couldnt', 'didn', 'didnt', 'doesn', 'doesnt', 'hadn', 'hadnt', 'hasn', 'hasnt', 'haven', 'havent', 'isn', 'isnt', 'ma', 'mightn', 'mightnt', 'mustn', 'mustnt', 'needn', 'neednt', 'shan', 'shant', 'shouldn', 'shouldnt', 'wasn', 'wasnt', 'weren', 'werent', 'won', 'wont', 'wouldn', 'wouldnt', 'im', 'ill', 'id', 'oh', 'cant', 'ive']\n"
          ]
        }
      ],
      "source": [
        "# we need to clean and update the NLTK stopwords for our data\n",
        "# we're stripping out punctuation entirely, which the stopwords are not equipped to handle\n",
        "# could optionally add music-centric stopwords ('oh', 'yeah', 'like', etc)\n",
        "\n",
        "temp_words = sw.words('english')\n",
        "stopwords = []\n",
        "additions = ['im', 'ill', 'id', 'oh', 'cant', 'ive']\n",
        "for w in temp_words:\n",
        "    stopwords.append(sl._clean(w))\n",
        "stopwords += additions\n",
        "print(stopwords)\n"
      ],
      "id": "rZe4wN0lawnW"
    },
    {
      "cell_type": "code",
      "source": [
        "for index,row in new_df.iterrows():\n",
        "  if index % 100 == 0:\n",
        "    print(index)\n",
        "\n",
        "  song = row['Lyrics']\n",
        "  x=song.find('\\n')\n",
        "  song2 = sl._clean(song[x+1:])\n",
        "  new_song = ''\n",
        "  for i in range(len(song2)):\n",
        "    char = song2[i]\n",
        "\n",
        "    if char == '\\n':\n",
        "      new_song += ' '\n",
        "    elif char == '(' or char == ')':\n",
        "      new_song += ''\n",
        "    else:\n",
        "      new_song += char\n",
        "\n",
        "\n",
        "    new_song = new_song.encode('ascii','ignore').decode()\n",
        "\n",
        "  song2 = new_song.split(' ')\n",
        "  song2 = list(filter(lambda x : x!='' and x not in stopwords, song2))\n",
        "  song2 = song2[:len(song2)-1]\n",
        "\n",
        "  new_df.at[index, 'Lyrics'] = song2\n"
      ],
      "metadata": {
        "id": "NXvZBjqH5iQa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "outputId": "faa8aa2e-281e-417f-bb18-0f52d1fd0d35"
      },
      "id": "NXvZBjqH5iQa",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3aaf307276d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msong\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Lyrics'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0msong2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msong\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mnew_song\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'find'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wordfreq = []\n",
        "for index,row in new_df.iterrows():\n",
        "  lyrics = row['Lyrics']\n",
        "\n",
        "  x = dict(collections.Counter(lyrics))\n",
        "  # mapped = []\n",
        "  # for k in x.keys():\n",
        "  #   mapped.append((k,x[k]))\n",
        "  \n",
        "  wordfreq.append(x)\n",
        "\n",
        "new_df['WordFreq'] = wordfreq"
      ],
      "metadata": {
        "id": "mQAXliGOJ_hx"
      },
      "id": "mQAXliGOJ_hx",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['UniqueWords']= new_df.apply(lambda row : len(row['WordFreq']), axis = 1)\n",
        "new_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "5t7YnPNfK6rg",
        "outputId": "1303df16-e040-45ed-ff4d-061d901a3181"
      },
      "id": "5t7YnPNfK6rg",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0         Artist                           Song  \\\n",
              "0              0  One Direction                        Perfect   \n",
              "1              1  One Direction               Story of My Life   \n",
              "2              2  One Direction                   Drag Me Down   \n",
              "3              3  One Direction       What Makes You Beautiful   \n",
              "4              4  One Direction                  Night Changes   \n",
              "...          ...            ...                            ...   \n",
              "4074        4074    Def Leppard              Action! Not Words   \n",
              "4075        4075    Def Leppard      Rock Rock (Till You Drop)   \n",
              "4076        4076    Def Leppard                          Slang   \n",
              "4077        4077    Def Leppard            Die Hard the Hunter   \n",
              "4078        4078    Def Leppard  High ‘n’ Dry (Saturday Night)   \n",
              "\n",
              "                                                 Lyrics  Genre  \\\n",
              "0     [might, never, knight, shinin, armor, might, n...    pop   \n",
              "1     [written, walls, stories, explain, leave, hear...    pop   \n",
              "2     [got, fire, heart, scared, dark, never, seen, ...    pop   \n",
              "3     [insecure, know, turning, heads, walk, door, n...    pop   \n",
              "4     [going, tonight, changes, something, red, moth...    pop   \n",
              "...                                                 ...    ...   \n",
              "4074  [sick, tired, damn, tv, gonna, make, movie, wa...  metal   \n",
              "4075  [ready, get, set, tear, place, apart, need, ti...  metal   \n",
              "4076  [sitting, dark, getting, taken, said, somethin...  metal   \n",
              "4077  [lets, welcome, home, soldier, boy, far, away,...  metal   \n",
              "4078  [saturday, feel, right, drinking, day, yes, go...  metal   \n",
              "\n",
              "                                               WordFreq  UniqueWords  \n",
              "0     {'might': 4, 'never': 4, 'knight': 1, 'shinin'...           71  \n",
              "1     {'written': 3, 'walls': 2, 'stories': 1, 'expl...           68  \n",
              "2     {'got': 4, 'fire': 2, 'heart': 2, 'scared': 2,...           37  \n",
              "3     {'insecure': 1, 'know': 18, 'turning': 1, 'hea...           54  \n",
              "4     {'going': 2, 'tonight': 3, 'changes': 8, 'some...           65  \n",
              "...                                                 ...          ...  \n",
              "4074  {'sick': 1, 'tired': 1, 'damn': 1, 'tv': 1, 'g...           61  \n",
              "4075  {'ready': 1, 'get': 2, 'set': 1, 'tear': 1, 'p...           74  \n",
              "4076  {'sitting': 1, 'dark': 1, 'getting': 1, 'taken...           41  \n",
              "4077  {'lets': 2, 'welcome': 2, 'home': 2, 'soldier'...           65  \n",
              "4078  {'saturday': 17, 'feel': 3, 'right': 1, 'drink...           45  \n",
              "\n",
              "[4078 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1f41c841-8234-462a-a62c-c2b4db1fe58d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Artist</th>\n",
              "      <th>Song</th>\n",
              "      <th>Lyrics</th>\n",
              "      <th>Genre</th>\n",
              "      <th>WordFreq</th>\n",
              "      <th>UniqueWords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>One Direction</td>\n",
              "      <td>Perfect</td>\n",
              "      <td>[might, never, knight, shinin, armor, might, n...</td>\n",
              "      <td>pop</td>\n",
              "      <td>{'might': 4, 'never': 4, 'knight': 1, 'shinin'...</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>One Direction</td>\n",
              "      <td>Story of My Life</td>\n",
              "      <td>[written, walls, stories, explain, leave, hear...</td>\n",
              "      <td>pop</td>\n",
              "      <td>{'written': 3, 'walls': 2, 'stories': 1, 'expl...</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>One Direction</td>\n",
              "      <td>Drag Me Down</td>\n",
              "      <td>[got, fire, heart, scared, dark, never, seen, ...</td>\n",
              "      <td>pop</td>\n",
              "      <td>{'got': 4, 'fire': 2, 'heart': 2, 'scared': 2,...</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>One Direction</td>\n",
              "      <td>What Makes You Beautiful</td>\n",
              "      <td>[insecure, know, turning, heads, walk, door, n...</td>\n",
              "      <td>pop</td>\n",
              "      <td>{'insecure': 1, 'know': 18, 'turning': 1, 'hea...</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>One Direction</td>\n",
              "      <td>Night Changes</td>\n",
              "      <td>[going, tonight, changes, something, red, moth...</td>\n",
              "      <td>pop</td>\n",
              "      <td>{'going': 2, 'tonight': 3, 'changes': 8, 'some...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4074</th>\n",
              "      <td>4074</td>\n",
              "      <td>Def Leppard</td>\n",
              "      <td>Action! Not Words</td>\n",
              "      <td>[sick, tired, damn, tv, gonna, make, movie, wa...</td>\n",
              "      <td>metal</td>\n",
              "      <td>{'sick': 1, 'tired': 1, 'damn': 1, 'tv': 1, 'g...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4075</th>\n",
              "      <td>4075</td>\n",
              "      <td>Def Leppard</td>\n",
              "      <td>Rock Rock (Till You Drop)</td>\n",
              "      <td>[ready, get, set, tear, place, apart, need, ti...</td>\n",
              "      <td>metal</td>\n",
              "      <td>{'ready': 1, 'get': 2, 'set': 1, 'tear': 1, 'p...</td>\n",
              "      <td>74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4076</th>\n",
              "      <td>4076</td>\n",
              "      <td>Def Leppard</td>\n",
              "      <td>Slang</td>\n",
              "      <td>[sitting, dark, getting, taken, said, somethin...</td>\n",
              "      <td>metal</td>\n",
              "      <td>{'sitting': 1, 'dark': 1, 'getting': 1, 'taken...</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4077</th>\n",
              "      <td>4077</td>\n",
              "      <td>Def Leppard</td>\n",
              "      <td>Die Hard the Hunter</td>\n",
              "      <td>[lets, welcome, home, soldier, boy, far, away,...</td>\n",
              "      <td>metal</td>\n",
              "      <td>{'lets': 2, 'welcome': 2, 'home': 2, 'soldier'...</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4078</th>\n",
              "      <td>4078</td>\n",
              "      <td>Def Leppard</td>\n",
              "      <td>High ‘n’ Dry (Saturday Night)</td>\n",
              "      <td>[saturday, feel, right, drinking, day, yes, go...</td>\n",
              "      <td>metal</td>\n",
              "      <td>{'saturday': 17, 'feel': 3, 'right': 1, 'drink...</td>\n",
              "      <td>45</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4078 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1f41c841-8234-462a-a62c-c2b4db1fe58d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1f41c841-8234-462a-a62c-c2b4db1fe58d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1f41c841-8234-462a-a62c-c2b4db1fe58d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "uniq_words = set()\n",
        "for x in new_df['WordFreq']:\n",
        "  uniq_words = uniq_words.union(x.keys())\n",
        "uniq_wordict = {k : 0 for k in uniq_words}"
      ],
      "metadata": {
        "id": "AhtEtNbEwmnH"
      },
      "id": "AhtEtNbEwmnH",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_df = new_df[['Genre', 'WordFreq', 'Artist', 'UniqueWords']]\n",
        "\n",
        "for index,row in word_df.iterrows():\n",
        "  for k in row['WordFreq']:\n",
        "    uniq_wordict[k] = row['WordFreq'][k]\n",
        "\n",
        "  word_df.at[index, 'WordFreq'] = uniq_wordict\n",
        "  word_df.at[index, 'Artist'] = list(uniq_wordict.values()) + [row['UniqueWords']]\n",
        "  uniq_wordict = {k : 0 for k in uniq_words}\n",
        "\n",
        "word_df = word_df.replace({'Artist':'WordFreqList'})\n"
      ],
      "metadata": {
        "id": "7-z_Fgxa1jsR"
      },
      "id": "7-z_Fgxa1jsR",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvjIQJlVh5El",
        "outputId": "95831e5d-5e69-48ab-f4a5-913dca418ae1"
      },
      "id": "qvjIQJlVh5El",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "142"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_df = word_df.rename(columns = {'Artist':'WordFreqList'})"
      ],
      "metadata": {
        "id": "Tnv2CZeGco9t"
      },
      "id": "Tnv2CZeGco9t",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make a 80/20 train/test split of lyric words tagged by origin genre\n",
        "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(list(word_df['WordFreqList']), list(word_df['Genre']), test_size=0.2)\n",
        "\n",
        "print(f'Split size: {len(X_test) / (len(X_test) + len(X_train))}\\nTest set: {len(X_test)}\\nTrain set: {len(X_train)}')"
      ],
      "metadata": {
        "id": "MrdPGQ_F85Qy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6670b445-cbbb-4e60-a293-3e9a6d9a37d2"
      },
      "id": "MrdPGQ_F85Qy",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split size: 0.20009808729769496\n",
            "Test set: 816\n",
            "Train set: 3262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[1][-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5gqe0QFr0l2",
        "outputId": "718a5251-4e9c-4ee1-f5f1-1bdbf4e7df5c"
      },
      "id": "c5gqe0QFr0l2",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = tree.DecisionTreeClassifier()\n",
        "clf.fit(X_train,Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCqVqnRI_kje",
        "outputId": "3b7037b9-533d-4611-d3c5-fca88d832f98"
      },
      "id": "cCqVqnRI_kje",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier()"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = clf.predict(X_test)"
      ],
      "metadata": {
        "id": "4nUh3qoxJjhH"
      },
      "id": "4nUh3qoxJjhH",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(preds == Y_test)/len(preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ItmRqJKJ0Va",
        "outputId": "be359428-02b9-41b6-ada2-09b3997b384e"
      },
      "id": "4ItmRqJKJ0Va",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3602941176470588"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "# STOP"
      ],
      "metadata": {
        "id": "GWOk4XcpwP5h"
      },
      "id": "GWOk4XcpwP5h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CXrImqRawnX",
        "outputId": "9cc9c891-4090-4edc-a16e-1b45bdb625b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imported 166 lines\n",
            "Identified 7 genres: {'soul_rb', 'alternative', 'rock', 'metal', 'rap_hiphop', 'pop', 'country'}\n",
            "Extracted 7 genres\n"
          ]
        }
      ],
      "source": [
        "# I'm opening the csv of lyrics from songlyrics.com, which is structured differently than the genius one.\n",
        "# might need to restructure this code (or the genius csv) if we want to use that too\n",
        "# the only difference is all the lyrics by each artist are combined into a single cell (as opposed to split by song)\n",
        "df = pd.read_csv('data/all_sl.csv')\n",
        "print(f'Imported {len(df)} lines')\n",
        "genres = set(df['Genre'])\n",
        "print(f'Identified {len(genres)} genres: {genres}')\n",
        "lyrics = defaultdict(str)\n",
        "for genre in genres:\n",
        "    for artist in list(df[df['Genre'] == genre]['Lyrics']): # grab each row (artist) and select the lyrics cell\n",
        "        lyrics[genre] += artist # combine each batch of lyrics into the respective genre in the dictionary\n",
        "print(f'Extracted {len(lyrics)} genres')"
      ],
      "id": "5CXrImqRawnX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNK8qUKlawnY",
        "outputId": "5f0af8aa-a661-4f0b-ffd8-0b97868483b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pop] Identified 7269 unique words\n",
            "[rap_hiphop] Identified 15104 unique words\n",
            "[rock] Identified 6416 unique words\n",
            "[metal] Identified 8963 unique words\n",
            "[alternative] Identified 5750 unique words\n",
            "[country] Identified 6533 unique words\n",
            "[soul_rb] Identified 4626 unique words\n"
          ]
        }
      ],
      "source": [
        "frequency_tables = {}\n",
        "words_uniq = {}\n",
        "lines_uniq = {}\n",
        "for (genre,lyric) in lyrics.items():\n",
        "    frequency_tables[genre] = sl.words_freq(lyric, stopwords)\n",
        "    words_uniq[genre] = sl.words(lyric, stopwords)\n",
        "    print(f'[{genre}] Identified {len(words_uniq[genre])} unique words')"
      ],
      "id": "MNK8qUKlawnY"
    },
    {
      "cell_type": "code",
      "source": [
        "len(lyrics['alternative'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aCzIv-Ai5zU",
        "outputId": "b2d9b473-1d4d-4361-9620-b9d77950599d"
      },
      "id": "2aCzIv-Ai5zU",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "703734"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyxLZ9lKawnZ",
        "outputId": "e4f4939e-2648-4d8e-b07a-69844249333f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### pop ###\n",
            "[('love', 2008), ('know', 1645), ('like', 1463), ('baby', 1121), ('got', 1087), ('yeah', 1053), ('go', 1007), ('get', 967), ('one', 868), ('cause', 867), ('let', 806), ('girl', 796), ('say', 727), ('make', 723), ('la', 709), ('want', 688), ('wanna', 667), ('time', 656), ('never', 643), ('need', 611), ('take', 606), ('right', 605), ('way', 580), ('heart', 573), ('see', 566)]\n",
            "### rap_hiphop ###\n",
            "[('like', 2874), ('got', 2079), ('get', 1991), ('nigga', 1790), ('know', 1750), ('aint', 1316), ('yeah', 1286), ('niggas', 1236), ('bitch', 1206), ('shit', 1184), ('fuck', 1143), ('love', 943), ('back', 891), ('see', 860), ('money', 799), ('go', 784), ('cause', 770), ('baby', 708), ('thats', 705), ('want', 702), ('man', 674), ('make', 669), ('em', 668), ('say', 660), ('right', 591)]\n",
            "### rock ###\n",
            "[('love', 1159), ('yeah', 869), ('know', 793), ('like', 679), ('got', 659), ('one', 628), ('away', 580), ('go', 551), ('get', 525), ('never', 525), ('time', 524), ('want', 520), ('come', 440), ('way', 432), ('well', 430), ('say', 423), ('baby', 422), ('take', 394), ('gonna', 347), ('see', 346), ('let', 333), ('give', 323), ('back', 309), ('life', 306), ('wanna', 302)]\n",
            "### metal ###\n",
            "[('one', 573), ('like', 565), ('never', 543), ('know', 507), ('time', 504), ('love', 494), ('see', 492), ('get', 473), ('away', 452), ('life', 449), ('take', 439), ('yeah', 434), ('let', 380), ('way', 368), ('die', 348), ('got', 348), ('feel', 343), ('go', 341), ('world', 337), ('eyes', 321), ('come', 316), ('inside', 303), ('say', 279), ('man', 274), ('want', 272)]\n",
            "### alternative ###\n",
            "[('know', 838), ('love', 678), ('time', 652), ('like', 599), ('go', 596), ('got', 543), ('one', 525), ('never', 506), ('take', 457), ('back', 447), ('away', 445), ('say', 440), ('come', 432), ('get', 418), ('want', 417), ('right', 405), ('see', 401), ('let', 376), ('yeah', 369), ('way', 369), ('cause', 368), ('na', 351), ('feel', 342), ('well', 325), ('make', 314)]\n",
            "### country ###\n",
            "[('like', 1033), ('love', 777), ('know', 714), ('got', 642), ('baby', 539), ('one', 524), ('little', 518), ('get', 516), ('yeah', 490), ('go', 488), ('time', 465), ('back', 452), ('aint', 434), ('never', 427), ('see', 418), ('gonna', 413), ('take', 396), ('well', 383), ('could', 376), ('night', 376), ('way', 367), ('cause', 365), ('man', 364), ('old', 354), ('away', 352)]\n",
            "### soul_rb ###\n",
            "[('love', 1492), ('baby', 1220), ('know', 971), ('yeah', 762), ('like', 627), ('got', 547), ('want', 477), ('come', 457), ('time', 439), ('one', 435), ('wanna', 435), ('go', 424), ('let', 395), ('make', 364), ('get', 350), ('say', 346), ('right', 310), ('way', 309), ('see', 307), ('girl', 306), ('cause', 300), ('day', 296), ('aint', 274), ('never', 273), ('good', 264)]\n"
          ]
        }
      ],
      "source": [
        "# as an example, print the top 25 most common terms from each genre!\n",
        "for genre in frequency_tables:\n",
        "    print(f'### {genre} ###\\n{sorted(frequency_tables[genre].items(), key=lambda x: x[1], reverse=True)[:25]}')"
      ],
      "id": "kyxLZ9lKawnZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "Ml5XQ3uSawnZ",
        "outputId": "4e8e4e75-23f3-436e-807a-7501608322f7"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5cd872ee20da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwords_uniq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mY\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenre\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'words_uniq' is not defined"
          ]
        }
      ],
      "source": [
        "# make a 80/20 train/test split of lyric words tagged by origin genre\n",
        "X = []\n",
        "Y = []\n",
        "for (genre,words) in words_uniq.items():\n",
        "    X += words\n",
        "    Y += [genre] * len(words)\n",
        "X_train, X_test, Y_train, Y_test = sk.model_selection.train_test_split(X, Y, test_size=0.2)\n",
        "print(f'Split size: {len(X_test) / (len(X_test) + len(X_train))}\\nTest set: {len(X_test)}\\nTrain set: {len(X_train)}')\n"
      ],
      "id": "Ml5XQ3uSawnZ"
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "filtered.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}