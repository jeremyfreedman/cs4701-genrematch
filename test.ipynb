{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kunalsheth2000/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/kunalsheth2000/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lyricsgenius as lg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Artist, Song, Lyrics, Genre]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['Artist', 'Song', 'Lyrics','Genre'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop = ['One Direction']\n",
    "# rap_hiphop = ['Fetty Wap', 'Migos', '21 Savage', '88GLAM', 'Roddy Rich', 'Lil Baby', 'Eminem', 'Snoop Dogg', 'Drake','Kanye West', 'Travis Scott', 'Dr. Dre','Lil Wayne' ,\n",
    "#        '50 Cent' ,'Jay-Z', 'Kendrick Lamar' ,'J. Cole' ,'Nas' ,'Kid Cudi' ,'Cardi B', 'Nicki Minaj', 'A$AP Rocky' ,'Pop Smoke', 'Meek Mill', 'Young Thug']\n",
    "# country = ['Tim McGraw', 'Blake Shelton', 'George Strait', 'Garth Brooks', 'Luke Bryan', 'Luke Combs', 'Kenny Chesney', 'Keith Urban', 'Johnny Cash', 'Carrie Underwood', \n",
    "#            'Brad Paisley', 'Merie Haggard', 'Jason Aldean', 'Dierks Bentley', 'Alan Jackson', 'Chris Stapleton', 'Kenny Rogers', 'Toby Keith', 'Darius Rucker', 'George Jones', \n",
    "#            'Willie Nelson', 'Miranda Lambert', 'Chris Young', 'Randy Travis', 'Thomas Rhett']\n",
    "# soul_rb = ['Stevie Wonder', 'Ray Charles', 'John Legend', 'Ne-Yo', 'Alicia Keys', 'Mariah Carey', 'Miguel', 'Bob Marley', 'Giveon', 'Otis Redding', 'Aretha Franklin', \n",
    "#                'Marvin Gaye', 'Al Green', 'Sam Cooke', 'Sza', 'Teddy Pendergrass', 'Commodores', 'Leon Bridges']\n",
    "# alternative = ['Nirvana', 'The Script', 'OneRepublic', 'Imagine Dragons', 'Coldplay', 'U2', 'Train', 'Weezer', 'Fall Out Boy', 'Paramore', 'Maroon 5', 'Arctic Monkeys', \n",
    "#                'Snow Patrol', 'Walk The Moon', 'Radiohead', 'Green Day', 'Cage The Elephant', 'The Strokes', 'The All-American Rejects', 'The Chemical Brothers', \n",
    "#                'Blink-182', 'Incubus', 'Simple Plan']\n",
    "# rock = ['Queen', 'Led Zeppelin', 'Rolling Stones', 'AC/DC', 'Guns Nâ€™ Roses', 'Red Hot Chili Peppers', 'The Eagles', 'Fleetwood Mac', 'The Doors', 'Pink Smith', \n",
    "#         'Aerosmith', 'Stevie Nicks', 'Journey', 'The Police', 'The Kings', 'The Who', 'Van Halen', 'Bob Dylan', 'The Beatles', 'Linkin Park', 'Nickelback', 'Tame Impala', \n",
    "#         'Foo Fighters', 'Bon Jovi', 'Leonard Cohen']\n",
    "# metal = ['Metallica', 'Black Sabbath', 'Judas Preist', 'Slayer', 'Death', 'Tool', 'Korn', 'Dream Theater', 'Slipknot', 'Pantera', 'Iron Maiden', 'Avenged Sevenfold', \n",
    "#          'Alice in Chains', 'Anthrax', 'Rage Against the Machine', 'Mastodon', 'Five Finger Death Punch', 'Rammstein', 'System of a Down', 'Machine Head', \n",
    "#          'Mercyful Fate', 'Manowar', 'Nightwish', 'Deep Purple', 'Def Leppard']\n",
    "\n",
    "genre_artists = {'pop':pop}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lg.Genius('Kazu51bV8gbOwO6RQpZA-ZQ-4iOWbGdiQADlWk6SRO6DGtoezXzRL6Qapzdpu-VJ', skip_non_songs=True)\n",
    "genius.excluded_terms=[\"(Remix)\", \"(Live)\"]\n",
    "genius.remove_section_headers = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by One Direction...\n",
      "\n",
      "Song 1: \"Perfect\"\n",
      "Song 2: \"Story of My Life\"\n",
      "\n",
      "Reached user-specified song limit (2).\n",
      "Done. Found 2 songs.\n"
     ]
    }
   ],
   "source": [
    "def get_lyrics(df, genre_artists, k):  # Write lyrics of k songs by each artist in arr\n",
    "    c = 0  # Counter\n",
    "    err = 0\n",
    "    for genre in genre_artists.keys():\n",
    "        for artist in genre_artists[genre]:\n",
    "            while True:\n",
    "                try:\n",
    "                    songs = (genius.search_artist(artist, max_songs=2, sort='popularity')).songs\n",
    "                    for song in songs:\n",
    "                        df = df.append({'Artist':song.artist , 'Song':song.title , 'Lyrics':song.lyrics , 'Genre':genre}, ignore_index = True)\n",
    "                    break\n",
    "                except:\n",
    "                    err += 1\n",
    "                    print('err',err)\n",
    "                    pass\n",
    "                # except:  #  Broad catch which will give us the name of artist and song that threw the exception\n",
    "                # print(f\"some exception at {name}: {c}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "new_df = get_lyrics(df, genre_artists, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Story of My Life Lyrics\\nWritten in these walls are the stories that I can't explain\\nI leave my heart open\\nBut it stays right here empty for days\\nShe told me in the morning\\nShe don't feel the same about us in her bones\\nIt seems to me that when I die\\nThese words will be written on my stone\\n\\nAnd I'll be gone, gone tonight\\nThe ground beneath my feet is open wide\\nThe way that I've been holding on too tight\\nWith nothing in between\\n\\nThe story of my life, I take her home\\nI drive all night to keep her warm\\nAnd time is frozen (The story of, the story of)\\nThe story of my life, I give her hope\\nI spend her love\\nUntil she's broke inside\\nThe story of my life (The story of, the story of)\\nWritten on these walls are the colors that I can't change\\nLeave my heart open\\nBut it stays right here in its cage\\nI know that in the morning, now\\nI'll see us in the light up on the hill\\nAlthough I am broken, my heart is untamed still\\n\\nAnd I'll be gone, gone tonight\\nThe fire beneath my feet is burning bright\\nThe way that I've been holding on so tight\\nWith nothing in between\\n\\nThe story of my life, I take her home\\nI drive all night to keep her warm\\nAnd time is frozen\\nThe story of my life (The story of, the story of)\\nThe story of my life, I give her hope\\nI spend her love\\nUntil she's broke inside\\nThe story of my life (The story of, the story of)\\n\\nAnd I've been waiting for this time to come around\\nBut, baby, running after you\\nIs like chasing the clouds\\nThe story of my life, I take her home\\nI drive all night to keep her warm\\nAnd time is frozen\\n\\nThe story of my life, I give her hope (Give her hope)\\nI spend her love until she's broke inside (Until she's broke inside)\\nThe story of my life\\n\\nThe story of my life\\nThe story of my life\\nThe story of my life186Embed\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song = new_df['Lyrics'][1]\n",
    "song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name', \"'s\"]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(\"my name's\")\n",
    "\n",
    "filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
