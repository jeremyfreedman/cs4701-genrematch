{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GenreMatch\n",
        "Data cleaning and model generation  \n",
        "*Jeremy Freedman, Reza Madhavan, Kunal Sheth*"
      ],
      "metadata": {
        "id": "MN4JcSLjawnT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!unzip Archive.zip"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdHUQFa3dgMx",
        "outputId": "a0254c9b-217b-45f7-bf43-3a89aa01dee0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!ls utils"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy9GICSqdrpH",
        "outputId": "14e938d0-d975-4709-ce9c-10562cc138cd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import utils.songlyrics as sl\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords as sw\n",
        "from nltk import download as nltk_download\n",
        "import matplotlib.pyplot as pyplot\n",
        "import sklearn as sk\n",
        "from sklearn import tree\n",
        "import collections\n",
        "import gc\n",
        "import math\n",
        "import pickle\n",
        "import json"
      ],
      "outputs": [],
      "metadata": {
        "id": "ZRQb4iM7awnV",
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "a=pd.read_csv('data/song_lyrics.csv').dropna()\n",
        "new_df = a.copy()\n",
        "head = new_df.head(5)"
      ],
      "outputs": [],
      "metadata": {
        "id": "S7jvCK5HjTtP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# download the NLTK stopwords list, if necessary\n",
        "nltk_download('stopwords')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtGsK4NbawnW",
        "outputId": "528a5e7e-cda7-4e1f-d316-6a5cbcf6c56b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# we need to clean and update the NLTK stopwords for our data\n",
        "# we're stripping out punctuation entirely, which the stopwords are not equipped to handle\n",
        "# could optionally add music-centric stopwords ('oh', 'yeah', 'like', etc)\n",
        "\n",
        "temp_words = sw.words('english')\n",
        "stopwords = []\n",
        "additions = ['im', 'ill', 'id', 'oh', 'cant', 'ive']\n",
        "for w in temp_words:\n",
        "    stopwords.append(sl._clean(w))\n",
        "stopwords += additions\n",
        "print(stopwords)\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZe4wN0lawnW",
        "outputId": "f31dbdc4-16f8-4b2b-9044-87b79d9a5eac"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "for index,row in new_df.iterrows():\n",
        "  if index % 100 == 0:\n",
        "    print(index)\n",
        "\n",
        "  song = row['Lyrics']\n",
        "  x=song.find('\\n')\n",
        "  song2 = sl._clean(song[x+1:])\n",
        "  new_song = ''\n",
        "  for i in range(len(song2)):\n",
        "    char = song2[i]\n",
        "\n",
        "    if char == '\\n':\n",
        "      new_song += ' '\n",
        "    elif char == '(' or char == ')':\n",
        "      new_song += ''\n",
        "    else:\n",
        "      new_song += char\n",
        "\n",
        "\n",
        "    new_song = new_song.encode('ascii','ignore').decode()\n",
        "\n",
        "  song2 = new_song.split(' ')\n",
        "  song2 = list(filter(lambda x : x!='' and x not in stopwords, song2))\n",
        "  song2 = song2[:len(song2)-1]\n",
        "\n",
        "  new_df.at[index, 'Lyrics'] = song2\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "NXvZBjqH5iQa",
        "outputId": "faa8aa2e-281e-417f-bb18-0f52d1fd0d35"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "wordfreq = []\n",
        "word_appearance_cnt = defaultdict(int) # how many songs contain word W? used for IDF\n",
        "for index,row in new_df.iterrows():\n",
        "  lyrics = row['Lyrics']\n",
        "  x = dict(collections.Counter(lyrics))\n",
        "  for w in x:\n",
        "    word_appearance_cnt[w] += 1\n",
        "  # mapped = []\n",
        "  # for k in x.keys():\n",
        "  #   mapped.append((k,x[k]))\n",
        "  wordfreq.append(x)\n",
        "# specify how many words (most popular first) to turn into features:\n",
        "top_words = {k : v for k, v in sorted(word_appearance_cnt.items(), key=lambda x: x[1], reverse=True)[:1200]}\n",
        "new_df['WordFreq'] = wordfreq"
      ],
      "outputs": [],
      "metadata": {
        "id": "mQAXliGOJ_hx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "new_df['UniqueWords']= new_df.apply(lambda row : len(row['WordFreq']), axis = 1)\n",
        "new_df"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "5t7YnPNfK6rg",
        "outputId": "1303df16-e040-45ed-ff4d-061d901a3181"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# uniq_words = set()\n",
        "# for x in new_df['WordFreq']:\n",
        "#   uniq_words = uniq_words.union(x.keys())\n",
        "uniq_wordict = {k : 0 for k in top_words.keys()}"
      ],
      "outputs": [],
      "metadata": {
        "id": "AhtEtNbEwmnH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "word_df = new_df[['Genre', 'WordFreq', 'Artist', 'UniqueWords']]\n",
        "\n",
        "for index,row in word_df.iterrows():\n",
        "  if index % 100 == 0:\n",
        "    print(f'\\r{100 * index // len(new_df)}%', end='')\n",
        "  for k in row['WordFreq']:\n",
        "    if k in top_words.keys():\n",
        "      # uniq_wordict[k] = row['WordFreq'][k] # original (raw count)\n",
        "      uniq_wordict[k] = row['WordFreq'][k] * math.log(len(new_df) / word_appearance_cnt[k]) # tf-idf\n",
        "\n",
        "  word_df.at[index, 'WordFreq'] = uniq_wordict\n",
        "  word_df.at[index, 'Artist'] = list(uniq_wordict.values()) + [row['UniqueWords']]\n",
        "  uniq_wordict = {k : 0 for k in top_words.keys()}\n",
        "print(f'\\rDone', end='')\n",
        "word_df = word_df.replace({'Artist':'WordFreqList'})\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "7-z_Fgxa1jsR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# free up memory\n",
        "gc.collect()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvjIQJlVh5El",
        "outputId": "95831e5d-5e69-48ab-f4a5-913dca418ae1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "word_df = word_df.rename(columns = {'Artist':'WordFreqList'})\n",
        "print(word_df)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Tnv2CZeGco9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# write wordlist to disk for frontend use\n",
        "print(f'total of {len(top_words.keys())} uniq words')\n",
        "with open('data/words.txt', 'w') as f:\n",
        "    top_words[\"SONG_CNT\"] = len(new_df)\n",
        "    f.write(str(top_words))\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "print(len(word_df.head(1)['WordFreqList'][0]))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# trying various splits\n",
        "x_split_plt = []\n",
        "y_split_plt = []\n",
        "for i in range(10, 91, 10):\n",
        "    X_train, X_test, Y_train, Y_test = \\\n",
        "        sk.model_selection.train_test_split(list(word_df['WordFreqList']), list(word_df['Genre']), test_size=0.01*i)\n",
        "    print(f'Split ratio: {len(X_test) / (len(X_test) + len(X_train))}')\n",
        "    x_split_plt.append(i)\n",
        "    clf = tree.DecisionTreeClassifier()\n",
        "    clf.fit(X_train,Y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    y_split_plt.append(np.sum(preds == Y_test)/len(preds))\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plotting split\n",
        "pyplot.plot(x_split_plt, y_split_plt)\n",
        "pyplot.title('split ratio vs prediction accuracy')\n",
        "pyplot.xlabel('% sample used for testing')\n",
        "pyplot.ylabel('prediction accuracy')\n",
        "pyplot.show()\n",
        "best_split = x_split_plt[y_split_plt.index(max(y_split_plt))] * 0.01\n",
        "print(f'Best split: {best_split}')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# trying various max depths\n",
        "x_depth_plt = []\n",
        "y_depth_plt = []\n",
        "X_train, X_test, Y_train, Y_test = \\\n",
        "        sk.model_selection.train_test_split(list(word_df['WordFreqList']), list(word_df['Genre']), test_size=best_split)\n",
        "for i in range(1,102, 5):\n",
        "    print(f'max depth {i}')\n",
        "    x_depth_plt.append(i)\n",
        "    clf = tree.DecisionTreeClassifier(max_depth=i)\n",
        "    clf.fit(X_train,Y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    y_depth_plt.append(np.sum(preds == Y_test)/len(preds))\n",
        "    print(f'actual depth: {clf.get_depth()}')\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCqVqnRI_kje",
        "outputId": "3b7037b9-533d-4611-d3c5-fca88d832f98"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plotting depth\n",
        "pyplot.plot(x_depth_plt, y_depth_plt)\n",
        "pyplot.title('max depth vs prediction accuracy')\n",
        "pyplot.xlabel('max tree depth')\n",
        "pyplot.ylabel('prediction accuracy')\n",
        "pyplot.show()\n",
        "best_depth = x_depth_plt[y_depth_plt.index(max(y_depth_plt))] \n",
        "print(f'Best max depth: {best_depth}')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# trying various min leaf sample sizes\n",
        "x_sample_plt = []\n",
        "y_sample_plt = []\n",
        "X_train, X_test, Y_train, Y_test = \\\n",
        "        sk.model_selection.train_test_split(list(word_df['WordFreqList']), list(word_df['Genre']), test_size=best_split)\n",
        "for i in range(1, 101, 10):\n",
        "    print(f'min leaf sample {i}')\n",
        "    x_sample_plt.append(i)\n",
        "    clf = tree.DecisionTreeClassifier(min_samples_leaf=i, max_depth=best_depth)\n",
        "    clf.fit(X_train,Y_train)\n",
        "    preds = clf.predict(X_test)\n",
        "    y_sample_plt.append(np.sum(preds == Y_test)/len(preds))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# plotting min leaf sample\n",
        "pyplot.plot(x_sample_plt, y_sample_plt)\n",
        "pyplot.title('minimum leaf sample vs prediction accuracy')\n",
        "pyplot.xlabel('minimum leaf sample')\n",
        "pyplot.ylabel('prediction accuracy')\n",
        "pyplot.show()\n",
        "best_leaf_sample = x_sample_plt[y_sample_plt.index(max(y_sample_plt))]\n",
        "print(f'Best min leaf sample: {best_leaf_sample}')"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# commit model to disk\n",
        "clf_final = tree.DecisionTreeClassifier(min_samples_leaf=best_leaf_sample, max_depth=best_depth)\n",
        "clf_final.fit(X_train,Y_train)\n",
        "with open('model_dtc.pkl', 'wb') as f:\n",
        "    pickle.dump(clf_final, f)\n",
        "# tree.plot_tree(clf_final)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# assess final accuracy\n",
        "preds = clf_final.predict(X_test)\n",
        "print(np.sum(preds == Y_test)/len(preds))"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "# STOP"
      ],
      "metadata": {
        "id": "GWOk4XcpwP5h"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "filtered.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.7 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}