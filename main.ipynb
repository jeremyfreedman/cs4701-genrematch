{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a52b1d",
   "metadata": {},
   "source": [
    "# GenreMatch\n",
    "Data cleaning and model generation  \n",
    "*Jeremy Freedman, Reza Madhavan, Kunal Sheth*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d22d3020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils.songlyrics as sl\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords as sw\n",
    "from nltk import download as nltk_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the NLTK stopwords list, if necessary\n",
    "nltk_download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e328787c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to clean and update the NLTK stopwords for our data\n",
    "# we're stripping out punctuation entirely, which the stopwords are not equipped to handle\n",
    "# could optionally add music-centric stopwords ('oh', 'yeah', 'like', etc)\n",
    "\n",
    "temp_words = sw.words('english')\n",
    "stopwords = []\n",
    "additions = ['im', 'ill', 'id', 'oh']\n",
    "for w in temp_words:\n",
    "    stopwords.append(sl._clean(w))\n",
    "stopwords += additions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1cac323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 166 lines\n",
      "Identified 7 genres: {'alternative', 'rock', 'soul_rb', 'rap_hiphop', 'country', 'metal', 'pop'}\n",
      "Extracted 7 genres\n"
     ]
    }
   ],
   "source": [
    "# I'm opening the csv of lyrics from songlyrics.com, which is structured differently than the genius one.\n",
    "# might need to restructure this code (or the genius csv) if we want to use that too\n",
    "# the only difference is all the lyrics by each artist are combined into a single cell (as opposed to split by song)\n",
    "df = pd.read_csv('data/all_sl.csv')\n",
    "print(f'Imported {len(df)} lines')\n",
    "genres = set(df['Genre'])\n",
    "print(f'Identified {len(genres)} genres: {genres}')\n",
    "lyrics = defaultdict(str)\n",
    "for genre in genres:\n",
    "    for artist in list(df[df['Genre'] == genre]['Lyrics']): # grab each row (artist) and select the lyrics cell\n",
    "        lyrics[genre] += artist # combine each batch of lyrics into the respective genre in the dictionary\n",
    "print(f'Extracted {len(lyrics)} genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71639a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[alternative] Identified 5752 unique words\n",
      "[rock] Identified 6418 unique words\n",
      "[soul_rb] Identified 4628 unique words\n",
      "[rap_hiphop] Identified 15106 unique words\n",
      "[country] Identified 6535 unique words\n",
      "[metal] Identified 8965 unique words\n",
      "[pop] Identified 7271 unique words\n"
     ]
    }
   ],
   "source": [
    "frequency_tables = {}\n",
    "words_uniq = {}\n",
    "for (genre,lyric) in lyrics.items():\n",
    "    frequency_tables[genre] = sl.words_freq(lyric, stopwords)\n",
    "    words_uniq[genre] = sl.words(lyric, stopwords)\n",
    "    print(f'[{genre}] Identified {len(words_uniq[genre])} unique words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "db403b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### alternative ###\n",
      "[('know', 838), ('love', 678), ('time', 652), ('like', 599), ('go', 596), ('got', 543), ('one', 525), ('cant', 522), ('never', 506), ('take', 457), ('back', 447), ('away', 445), ('say', 440), ('come', 432), ('get', 418), ('want', 417), ('right', 405), ('see', 401), ('let', 376), ('yeah', 369), ('way', 369), ('cause', 368), ('na', 351), ('feel', 342), ('ive', 331)]\n",
      "### rock ###\n",
      "[('love', 1159), ('yeah', 869), ('know', 793), ('like', 679), ('got', 659), ('one', 628), ('away', 580), ('go', 551), ('get', 525), ('never', 525), ('time', 524), ('want', 520), ('cant', 460), ('come', 440), ('way', 432), ('well', 430), ('say', 423), ('baby', 422), ('ive', 407), ('take', 394), ('gonna', 347), ('see', 346), ('let', 333), ('give', 323), ('back', 309)]\n",
      "### soul_rb ###\n",
      "[('love', 1492), ('baby', 1220), ('know', 971), ('yeah', 762), ('like', 627), ('got', 547), ('want', 477), ('come', 457), ('time', 439), ('one', 435), ('wanna', 435), ('go', 424), ('let', 395), ('cant', 382), ('make', 364), ('get', 350), ('say', 346), ('right', 310), ('way', 309), ('see', 307), ('girl', 306), ('cause', 300), ('day', 296), ('aint', 274), ('never', 273)]\n",
      "### rap_hiphop ###\n",
      "[('like', 2874), ('got', 2079), ('get', 1991), ('nigga', 1790), ('know', 1750), ('aint', 1316), ('yeah', 1286), ('niggas', 1236), ('bitch', 1206), ('shit', 1184), ('fuck', 1143), ('love', 943), ('back', 891), ('see', 860), ('money', 799), ('go', 784), ('cause', 770), ('baby', 708), ('thats', 705), ('want', 702), ('man', 674), ('make', 669), ('em', 668), ('say', 660), ('right', 591)]\n",
      "### country ###\n",
      "[('like', 1033), ('love', 777), ('know', 714), ('got', 642), ('baby', 539), ('one', 524), ('little', 518), ('get', 516), ('yeah', 490), ('go', 488), ('time', 465), ('back', 452), ('aint', 434), ('never', 427), ('ive', 424), ('see', 418), ('gonna', 413), ('take', 396), ('well', 383), ('could', 376), ('night', 376), ('way', 367), ('cant', 365), ('cause', 365), ('man', 364)]\n",
      "### metal ###\n",
      "[('one', 573), ('like', 565), ('never', 543), ('cant', 508), ('know', 507), ('time', 504), ('love', 494), ('see', 492), ('get', 473), ('away', 452), ('life', 449), ('take', 439), ('yeah', 434), ('let', 380), ('way', 368), ('die', 348), ('got', 348), ('feel', 343), ('go', 341), ('world', 337), ('eyes', 321), ('come', 316), ('ive', 314), ('inside', 303), ('say', 279)]\n",
      "### pop ###\n",
      "[('love', 2008), ('know', 1645), ('like', 1463), ('baby', 1121), ('got', 1087), ('yeah', 1053), ('go', 1007), ('get', 967), ('one', 868), ('cause', 867), ('let', 806), ('girl', 796), ('say', 727), ('make', 723), ('la', 709), ('want', 688), ('wanna', 667), ('time', 656), ('never', 643), ('need', 611), ('take', 606), ('right', 605), ('way', 580), ('heart', 573), ('cant', 568)]\n"
     ]
    }
   ],
   "source": [
    "# as an example, print the top 25 most common terms from each genre!\n",
    "for genre in frequency_tables:\n",
    "    print(f'### {genre} ###\\n{sorted(frequency_tables[genre].items(), key=lambda x: x[1], reverse=True)[:25]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130471ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
