{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a52b1d",
   "metadata": {},
   "source": [
    "# GenreMatch\n",
    "Data cleaning and model generation  \n",
    "*Jeremy Freedman, Reza Madhavan, Kunal Sheth*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d22d3020",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils.songlyrics as sl\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import download as nltk_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e328787c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'youre', 'youve', 'youll', 'youd', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'shes', 'her', 'hers', 'herself', 'it', 'its', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'thatll', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'dont', 'should', 'shouldve', 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', 'arent', 'couldn', 'couldnt', 'didn', 'didnt', 'doesn', 'doesnt', 'hadn', 'hadnt', 'hasn', 'hasnt', 'haven', 'havent', 'isn', 'isnt', 'ma', 'mightn', 'mightnt', 'mustn', 'mustnt', 'needn', 'neednt', 'shan', 'shant', 'shouldn', 'shouldnt', 'wasn', 'wasnt', 'weren', 'werent', 'won', 'wont', 'wouldn', 'wouldnt', 'im']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jerem/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# we need to clean and update the NLTK stopwords for our data\n",
    "# we're stripping out punctuation entirely, which the stopwords are not equipped to handle\n",
    "\n",
    "nltk_download('stopwords')\n",
    "temp_words = stopwords.words('english')\n",
    "words = []\n",
    "for w in temp_words:\n",
    "    words.append(sl._clean(w))\n",
    "words.append('im')\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cac323c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 166 lines\n",
      "Identified 7 genres: {'rap_hiphop', 'alternative', 'pop', 'metal', 'country', 'rock', 'soul_rb'}\n",
      "Extracted 7 genres\n"
     ]
    }
   ],
   "source": [
    "# I'm opening the csv of lyrics from songlyrics.com, which is structured differently than the genius one.\n",
    "# might need to restructure this code (or the genius csv) if we want to use that too\n",
    "# the only difference is all the lyrics by each artist are combined into a single cell (as opposed to split by song)\n",
    "df = pd.read_csv('all_sl.csv')\n",
    "print(f'Imported {len(df)} lines')\n",
    "genres = set(df['Genre'])\n",
    "print(f'Identified {len(genres)} genres: {genres}')\n",
    "lyrics = defaultdict(str)\n",
    "for genre in genres:\n",
    "    for artist in list(df[df['Genre'] == genre]['Lyrics']): # grab each row (artist) and select the lyrics cell\n",
    "        lyrics[genre] += artist # combine each batch of lyrics into the respective genre in the dictionary\n",
    "print(f'Extracted {len(lyrics)} genres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71639a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_tables = {}\n",
    "words_uniq = {}\n",
    "for (genre,lyric) in lyrics.items():\n",
    "    frequency_tables[genre] = sl.words_freq(lyric, words)\n",
    "    words_uniq[genre] = sl.words(lyric, words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db403b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### rap_hiphop ###\n",
      "[('like', 2874), ('got', 2079), ('get', 1991), ('nigga', 1790), ('know', 1750), ('aint', 1316), ('yeah', 1286), ('niggas', 1236), ('bitch', 1206), ('shit', 1184), ('fuck', 1143), ('love', 943), ('back', 891), ('see', 860), ('money', 799), ('go', 784), ('cause', 770), ('baby', 708), ('thats', 705), ('want', 702), ('man', 674), ('make', 669), ('em', 668), ('say', 660), ('oh', 600)]\n",
      "### alternative ###\n",
      "[('oh', 1182), ('know', 838), ('love', 678), ('time', 652), ('like', 599), ('go', 596), ('got', 543), ('one', 525), ('cant', 522), ('never', 506), ('take', 457), ('ill', 453), ('back', 447), ('away', 445), ('say', 440), ('come', 432), ('get', 418), ('want', 417), ('right', 405), ('see', 401), ('let', 376), ('yeah', 369), ('way', 369), ('cause', 368), ('na', 351)]\n",
      "### pop ###\n",
      "[('love', 2008), ('know', 1645), ('like', 1463), ('oh', 1424), ('baby', 1121), ('got', 1087), ('yeah', 1053), ('go', 1007), ('get', 967), ('one', 868), ('cause', 867), ('let', 806), ('girl', 796), ('say', 727), ('make', 723), ('la', 709), ('want', 688), ('wanna', 667), ('time', 656), ('never', 643), ('need', 611), ('take', 606), ('right', 605), ('way', 580), ('heart', 573)]\n",
      "### metal ###\n",
      "[('one', 573), ('like', 565), ('never', 543), ('cant', 508), ('know', 507), ('time', 504), ('oh', 500), ('love', 494), ('see', 492), ('get', 473), ('away', 452), ('life', 449), ('take', 439), ('yeah', 434), ('let', 380), ('way', 368), ('die', 348), ('got', 348), ('feel', 343), ('go', 341), ('world', 337), ('eyes', 321), ('come', 316), ('ive', 314), ('inside', 303)]\n",
      "### country ###\n",
      "[('like', 1033), ('love', 777), ('know', 714), ('got', 642), ('baby', 539), ('one', 524), ('little', 518), ('get', 516), ('yeah', 490), ('go', 488), ('time', 465), ('ill', 460), ('back', 452), ('oh', 434), ('aint', 434), ('never', 427), ('ive', 424), ('see', 418), ('gonna', 413), ('take', 396), ('well', 383), ('could', 376), ('night', 376), ('way', 367), ('cant', 365)]\n",
      "### rock ###\n",
      "[('love', 1159), ('yeah', 869), ('know', 793), ('oh', 760), ('like', 679), ('got', 659), ('one', 628), ('away', 580), ('go', 551), ('get', 525), ('never', 525), ('time', 524), ('want', 520), ('cant', 460), ('come', 440), ('way', 432), ('well', 430), ('say', 423), ('baby', 422), ('ill', 409), ('ive', 407), ('take', 394), ('gonna', 347), ('see', 346), ('let', 333)]\n",
      "### soul_rb ###\n",
      "[('love', 1492), ('baby', 1220), ('oh', 1090), ('know', 971), ('yeah', 762), ('like', 627), ('got', 547), ('want', 477), ('come', 457), ('time', 439), ('one', 435), ('wanna', 435), ('go', 424), ('let', 395), ('cant', 382), ('make', 364), ('get', 350), ('say', 346), ('right', 310), ('way', 309), ('see', 307), ('girl', 306), ('cause', 300), ('day', 296), ('ill', 293)]\n"
     ]
    }
   ],
   "source": [
    "# as an example, print the top 25 most common terms from each genre!\n",
    "for genre in frequency_tables:\n",
    "    print(f'### {genre} ###\\n{sorted(frequency_tables[genre].items(), key=lambda x: x[1], reverse=True)[:25]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
